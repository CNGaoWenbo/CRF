{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac64af12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c722a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package           Version\n",
      "----------------- ---------\n",
      "backcall          0.2.0\n",
      "certifi           2022.12.7\n",
      "colorama          0.4.6\n",
      "debugpy           1.5.1\n",
      "decorator         5.1.1\n",
      "entrypoints       0.4\n",
      "ipykernel         6.16.2\n",
      "ipython           7.31.1\n",
      "jedi              0.18.1\n",
      "jupyter_client    7.4.9\n",
      "jupyter_core      4.11.2\n",
      "matplotlib-inline 0.1.6\n",
      "mkl-fft           1.3.1\n",
      "mkl-random        1.2.2\n",
      "mkl-service       2.4.0\n",
      "nest-asyncio      1.5.6\n",
      "numpy             1.21.5\n",
      "packaging         22.0\n",
      "parso             0.8.3\n",
      "pickleshare       0.7.5\n",
      "pip               22.3.1\n",
      "prompt-toolkit    3.0.36\n",
      "psutil            5.9.0\n",
      "Pygments          2.11.2\n",
      "python-dateutil   2.8.2\n",
      "pywin32           305.1\n",
      "pyzmq             23.2.0\n",
      "scipy             1.7.3\n",
      "setuptools        65.6.3\n",
      "six               1.16.0\n",
      "tornado           6.2\n",
      "traitlets         5.7.1\n",
      "wcwidth           0.2.5\n",
      "wheel             0.38.4\n",
      "wincertstore      0.2\n"
     ]
    }
   ],
   "source": [
    "! pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa8b05c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Module for inference in fully-connected CRFs.\n",
    "\n",
    "Author: Leonard Bruns (2019)\n",
    "\"\"\"\n",
    "\n",
    "import typing\n",
    "import time\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf98a2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CrfParameters:\n",
    "    \"\"\"Parameters for fully connected CRF with Gaussian kernels.\"\"\"\n",
    "\n",
    "    # Weights for each kernel.\n",
    "    kernel_weights: typing.List = field(default_factory=lambda: [10, 5])\n",
    "    # Spatial standard deviation for appearance kernel.\n",
    "    theta_alpha: float = 60\n",
    "    # Color standard deviation for appearance kernel.\n",
    "    theta_beta: float = 10\n",
    "    # Spatial standard deviation for smoothness kernel.\n",
    "    theta_gamma: float = 1\n",
    "    # Whether to use naive or efficient message passing.\n",
    "    efficient_message_passing: bool = True\n",
    "    # Factor to downsample the spatial dimensions for the 5D representation.\n",
    "    spatial_downsampling: float = 15\n",
    "    # Factor to downsample the range dimensions for the 5D representation.\n",
    "    range_downsampling: float = 15\n",
    "    # Number of iterations to perform.\n",
    "    iterations: int = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16ea02fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def appearance_kernel(\n",
    "    x_1: int,\n",
    "    y_1: int,\n",
    "    p_1: np.ndarray,\n",
    "    x_2: int,\n",
    "    y_2: int,\n",
    "    p_2: np.ndarray,\n",
    "    theta_alpha: float,\n",
    "    theta_beta: float,\n",
    ") -> float:\n",
    "    \"\"\"Compute appearance kernel.\n",
    "\n",
    "    Args:\n",
    "        x_1: X coordinate of first pixel.\n",
    "        y_1: Y coordinate of first pixel.\n",
    "        p_1: Color vector of first pixel.\n",
    "        x_2: X coordinate of second pixel.\n",
    "        y_2: Y coordinate of second pixel.\n",
    "        p_2: Color vector of second pixel.\n",
    "        theta_alpha: Standard deviation for the position.\n",
    "        theta_beta: Standard deviation for the color.\n",
    "\n",
    "    Returns:\n",
    "        The output of the appearence kernel.\n",
    "    \"\"\"\n",
    "    return np.exp(\n",
    "        -((x_1 - x_2) ** 2.0 + (y_1 - y_2) ** 2.0) / (2.0 * theta_alpha ** 2.0)\n",
    "        - np.sum((p_1 - p_2) ** 2.0) / (2.0 * theta_beta ** 2.0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27cdfaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothness_kernel(\n",
    "    x_1: int,\n",
    "    y_1: int,\n",
    "    p_1: np.ndarray,\n",
    "    x_2: int,\n",
    "    y_2: int,\n",
    "    p_2: np.ndarray,\n",
    "    theta_gamma: float,\n",
    ") -> float:\n",
    "    \"\"\"Compute smoothness kernel.\n",
    "\n",
    "    Args:\n",
    "        x_1: X coordinate of first pixel.\n",
    "        y_1: Y coordinate of first pixel.\n",
    "        p_1: Color vector of first pixel.\n",
    "        x_2: X coordinate of second pixel.\n",
    "        y_2: Y coordinate of second pixel.\n",
    "        p_2: Color vector of second pixel.\n",
    "        theta_gamma: Standard deviation for the position.\n",
    "\n",
    "    Returns:\n",
    "        The output of the smoothness kernel.\n",
    "    \"\"\"\n",
    "    del p_1, p_2\n",
    "    return np.exp(\n",
    "        -((x_1 - x_2) ** 2.0 + (y_1 - y_2) ** 2.0) / (2.0 * theta_gamma ** 2.0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95992662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(potentials: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Normalize potentials such that output is a valid pixelwise distribution.\n",
    "\n",
    "    Args:\n",
    "        potentials: Array of potentials. Shape (H,W,N).\n",
    "\n",
    "    Returns:\n",
    "        Probability array with same shape as potentials.\n",
    "        Probabilities sum up to 1 at every slice (i,j,:).\n",
    "    \"\"\"\n",
    "    # TODO: implement normalization here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa32c3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_passing(\n",
    "    image: np.ndarray,\n",
    "    current_probabilities: np.ndarray,\n",
    "    kernel_functions: typing.List[\n",
    "        typing.Callable[[int, int, np.ndarray, int, int, np.ndarray], float]\n",
    "    ],\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Perform \"message passing\" as the first step of the inference loop.\n",
    "\n",
    "    Args:\n",
    "        image:\n",
    "            Array of size ROWS x COLUMNS x CHANNELS, representing the image used to\n",
    "            compute the kernel.\n",
    "        current_probabilities:\n",
    "            Array of size ROWS x COLUMNS x CLASSES, representing the current\n",
    "            probabilities.\n",
    "        kernel_functions: The kernel functions defining the edge potential.\n",
    "\n",
    "    Returns:\n",
    "        Array of size ROWS x COLUMNS x CLASSES x KERNELS, representing the intermediate\n",
    "        result of message passing for each kernel.\n",
    "    \"\"\"\n",
    "    # naive version\n",
    "    rows = image.shape[0]\n",
    "    cols = image.shape[1]\n",
    "    classes = current_probabilities.shape[2]\n",
    "    result = np.zeros(\n",
    "        (\n",
    "            current_probabilities.shape[0],\n",
    "            current_probabilities.shape[1],\n",
    "            current_probabilities.shape[2],\n",
    "            len(kernel_functions),\n",
    "        ),\n",
    "        dtype=float,\n",
    "    )\n",
    "\n",
    "    # TODO implement naive message passing (using loops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec862432",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (3856038175.py, line 84)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [8]\u001b[1;36m\u001b[0m\n\u001b[1;33m    if kernel_id == 1: # smoothness kernel\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def efficient_message_passing(\n",
    "    image: np.ndarray,\n",
    "    current_probabilities: np.ndarray,\n",
    "    spatial_downsampling: float,\n",
    "    range_downsampling: float,\n",
    "    theta_alpha: float,\n",
    "    theta_beta: float,\n",
    "    theta_gamma: float,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Perform efficient \"message passing\" by downsampling and convolution in 5D.\n",
    "\n",
    "    This assumes two kernels: an appearance kernel based on theta_alpha and theta_beta,\n",
    "    and a smoothness kernel based on theta_gamma.\n",
    "\n",
    "    Args:\n",
    "        image:\n",
    "            Array of size ROWS x COLUMNS x CHANNELS, representing the image used to\n",
    "            compute the kernel.\n",
    "        current_probabilities:\n",
    "            Array of size ROWS x COLUMNS x CLASSES, representing the current\n",
    "            probabilities.\n",
    "        spatial_downsampling:\n",
    "            Factor to downsample the spatial dimensions for the 5D representation.\n",
    "        range_downsampling:\n",
    "            Factor to downsample the range dimensions for the 5D representation.\n",
    "        theta_alpha: Spatial standard deviation for the appearance kernel.\n",
    "        theta_beta: Color standard deviation for the appearance kernel.\n",
    "        theta_gamma: Spatial stadnard deviation for the smoothness kernel.\n",
    "\n",
    "    Returns:\n",
    "        Array of size ROWS x COLUMNS x CLASSES x KERNELS, representing the intermediate\n",
    "        result of message passing for each kernel.\n",
    "    \"\"\"\n",
    "    t_0 = time.time()\n",
    "\n",
    "    rows = image.shape[0]\n",
    "    cols = image.shape[1]\n",
    "    classes = current_probabilities.shape[2]\n",
    "    color_range = 255\n",
    "\n",
    "    ds_rows = int(np.ceil(rows / spatial_downsampling))\n",
    "    ds_cols = int(np.ceil(cols / spatial_downsampling))\n",
    "    ds_range = int(np.ceil(color_range / range_downsampling))\n",
    "\n",
    "    print(f\"Downsampled to: {ds_rows}x{ds_cols}x{ds_range}\")\n",
    "\n",
    "    result = np.zeros(\n",
    "        (\n",
    "            current_probabilities.shape[0],\n",
    "            current_probabilities.shape[1],\n",
    "            current_probabilities.shape[2],\n",
    "            2,\n",
    "        ),\n",
    "        dtype=float,\n",
    "    )\n",
    "\n",
    "    # precompute indices\n",
    "    indices_list = []\n",
    "    for row in np.arange(rows):\n",
    "        for col in np.arange(cols):\n",
    "            indices_list.append(\n",
    "                (row, col, image[row, col, 0], image[row, col, 1], image[row, col, 2])\n",
    "            )\n",
    "    indices_list = np.array(indices_list, dtype=np.float)\n",
    "    indices_list[:, 0:2] = indices_list[:, 0:2] / float(spatial_downsampling)\n",
    "    indices_list[:, 2:] = indices_list[:, 2:] / float(range_downsampling)\n",
    "    indices_list = np.round(indices_list).astype(np.int)\n",
    "\n",
    "    for class_id in np.arange(classes):\n",
    "        # allocate 5D feature space\n",
    "        feature_space = np.zeros((ds_rows+1, ds_cols+1, ds_range+1, ds_range+1, ds_range+1))\n",
    "\n",
    "        # downsample with box filter and go to 5D space at same time\n",
    "        # Hint: use indices list for this and only loop over row and col\n",
    "\n",
    "        # TODO: implement downsampling here\n",
    "\n",
    "        for kernel_id in np.arange(2):\n",
    "            if kernel_id == 0: # appearance kernel\n",
    "                # TODO: apply appearance kernel as a gaussian filter\n",
    "                # Hint 1: use gaussian_filter from scipy.ndimage\n",
    "                # Hint 2: remember to adjust parameters for downsampling\n",
    "\n",
    "            if kernel_id == 1: # smoothness kernel\n",
    "                # TODO: apply smoothness kernel as a gaussian filter\n",
    "                # Hint 1: use gaussian_filter from scipy.ndimage\n",
    "                # Hint 2: do we need a 5D convolution for the smoothness kernel?\n",
    "\n",
    "            # upsample with simple look up (no interpolation for simplicity)\n",
    "            # TODO: implement upsample here, reverse to downsample\n",
    "            # Hint: do we actually need this for both kernels? move it if not\n",
    "\n",
    "    t_1 = time.time()\n",
    "    print(f\"Efficient message passing took {t_1-t_0}s\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7d26af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compatibility_transform(\n",
    "    q_tilde: np.ndarray, weights: typing.List[float]\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Perform compatability transform as part of the inference loop.\n",
    "\n",
    "    Args:\n",
    "        q_tilde:\n",
    "            Array of size ROWS x COLUMNS x CLASSES x KERNELS, representing the\n",
    "            intermediate result of message passing for each kernel.\n",
    "        weights: Weights of each kernel.\n",
    "\n",
    "    Returns:\n",
    "        Array of size ROWS x COLUMNS x CLASSES, representing the result after combining\n",
    "        the kernels and applying the label compatability function (here: Potts model).\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: implement compatability transform (try with matrix operations only)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64709732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_update(q_hat: np.ndarray, unary_potential: np.ndarray):\n",
    "    \"\"\"Perform local update as part of the interefence loop.\n",
    "\n",
    "    Args:\n",
    "        q_hat:\n",
    "            Array of size ROWS x COLUMNS x CLASSES, representing the intermediate result\n",
    "            after combining the kernels and applying the label compatability function.\n",
    "        unary_potential:\n",
    "            Array of size ROWS x COLUMNS x CLASSES, representing the prior energy for\n",
    "            each pixel and class from a different source.\n",
    "    Returns:\n",
    "        Array of size ROWS x COLUMNS x CLASSES, representing the probabilities for each\n",
    "        pixel and class.\n",
    "    \"\"\"\n",
    "    # TODO: implement local update\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57f2ca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(\n",
    "    image: np.ndarray, initial_probabilities: np.ndarray, params: CrfParameters\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Perform inference in fully connected CRF with Gaussian edge potentials.\n",
    "\n",
    "    Args:\n",
    "        image:\n",
    "            Array of size ROWS x COLUMNS x CHANNELS, representing the image used the\n",
    "            features.\n",
    "        initial_probabilities:\n",
    "            Initial pixelwise probabilities for each class. Used to initialize unary\n",
    "            potential.\n",
    "        params:\n",
    "            Parameter class for fully connected CRFs (see CrfParameters documentation).\n",
    "    Return:\n",
    "        Array of size ROWS x COLS x CLASSES\n",
    "    \"\"\"\n",
    "    # define kernels\n",
    "    kernels = [\n",
    "        lambda x1, y1, p1, x2, y2, p2: appearance_kernel(\n",
    "            x1, y1, p1, x2, y2, p2, params.theta_alpha, params.theta_beta\n",
    "        ),\n",
    "        lambda x1, y1, p1, x2, y2, p2: smoothness_kernel(\n",
    "            x1, y1, p1, x2, y2, p2, params.theta_gamma\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # initialize\n",
    "    current_probabilities = initial_probabilities\n",
    "\n",
    "    unary_potential = -np.log(current_probabilities)\n",
    "\n",
    "    for _ in np.arange(params.iterations):\n",
    "        if params.efficient_message_passing:\n",
    "            q_tilde = efficient_message_passing(\n",
    "                image,\n",
    "                current_probabilities,\n",
    "                spatial_downsampling=params.spatial_downsampling,\n",
    "                range_downsampling=params.range_downsampling,\n",
    "                theta_alpha=params.theta_alpha,\n",
    "                theta_beta=params.theta_beta,\n",
    "                theta_gamma=params.theta_gamma,\n",
    "            )\n",
    "        else:\n",
    "            q_tilde = message_passing(image, current_probabilities, kernels)\n",
    "        q_hat = compatibility_transform(q_tilde, params.kernel_weights)\n",
    "        unnormalized_probabilities = local_update(q_hat, unary_potential)\n",
    "        current_probabilities = normalize(unnormalized_probabilities)\n",
    "\n",
    "    return current_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ef406d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test() -> None:\n",
    "    \"\"\"Runs simple tests to check functions in this file.\"\"\"\n",
    "    test_input = np.array([[[0.1, 0.1], [0.1, 0.1]], [[0.1, 0.4], [0.2, 0.3]]])\n",
    "    test_expected = np.array([[[0.5, 0.5], [0.5, 0.5]], [[0.2, 0.8], [0.4, 0.6]]])\n",
    "    test_out = normalize(test_input)\n",
    "\n",
    "    assert np.all(test_expected == test_out)\n",
    "    print(\"Test of normalize successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8a989a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
